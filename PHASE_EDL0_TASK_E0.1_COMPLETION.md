# Phase EDL-0 任务 E0.1 完成报告

**任务**: 定义 EDL 训练数据 Schema  
**完成时间**: 2025-12-11  
**状态**: ✅ 完成  

---

## 📋 任务概述

**目标**: 为 EDL（Evidential Deep Learning）模型定义清晰的训练数据格式、特征和标签，为后续数据导出和模型训练奠定基础。

**交付物**: `docs/EDL_TRAINING_DATA_DESIGN.md`

---

## 📊 设计内容总结

### 1. 输入特征（Features）- 共 10 维

#### 环保特征（8 维）
| 特征 | 范围 | 单位 | 说明 |
|------|------|------|------|
| `lat` | [-90, 90] | 度 | 纬度 |
| `lon` | [-180, 180] | 度 | 经度 |
| `month` | [1, 12] | - | 月份 |
| `dayofyear` | [1, 366] | - | 一年中的第几天 |
| `sic` | [0, 100] | % | 海冰浓度 |
| `ice_thickness_m` | [0, 5] | 米 | 海冰厚度 |
| `wave_swh` | [0, 15] | 米 | 波浪显著波高 |
| `ais_density` | [0, 1] | 归一化 | AIS 船舶密度 |

#### 船舶特征（2 维）
| 特征 | 范围 | 说明 |
|------|------|------|
| `vessel_class_id` | [0, 2] | 船舶等级：0=Handy, 1=Panamax, 2=Ice-class |
| `distance_to_coast_m` | [0, ∞) | 到海岸距离（可选） |

### 2. 输出标签（Targets）

#### 简单版本：二分类（现阶段）
```
label_safe_risky: {0, 1}
  0 = Safe（安全）
  1 = Risky（风险）
```

**Safe 定义**:
- `sic < 30%` AND `ice_thickness_m < 1.0` AND `wave_swh < 4.0` AND `ais_density > 0.1`

**Risky 定义**:
- `sic >= 70%` OR `ice_thickness_m >= 2.0` OR `wave_swh >= 5.0` OR `ais_density < 0.05`

**边界情况**: 使用风险评分 = 0.3×(sic/100) + 0.3×(ice_thickness_m/3) + 0.2×(wave_swh/6) + 0.2×(1-ais_density)
- 评分 < 0.4 → Safe
- 评分 >= 0.4 → Risky

#### 扩展版本：多类分类（后续）
```
label_ice_zone: {0, 1, 2}
  0 = Open Water（开阔水域）
  1 = Marginal Ice Zone（边际冰区）
  2 = Heavy Ice（密集冰区）
```

### 3. 文件格式

**推荐格式**: Parquet（列式存储）
- 压缩率高（相比 CSV 节省 50-80%）
- 支持分布式处理
- 读取速度快

**文件组织**:
```
data/edl_training/
├── train_2024_2025.parquet
├── val_2024_2025.parquet
├── test_2024_2025.parquet
└── metadata.json
```

**Parquet 列定义**:
- lat, lon, month, dayofyear
- sic, ice_thickness_m, wave_swh, ais_density
- vessel_class_id, distance_to_coast_m
- label_safe_risky, timestamp

### 4. 元数据规范

包含以下信息：
- 数据集版本和创建时间
- 训练/验证/测试集的样本数和时间范围
- 特征维度和目标类别
- 数据源和预处理方法
- 类别分布统计

---

## 🎯 设计亮点

### ✅ 完整性
- 覆盖环保特征 + 船舶特征
- 包含特征范围、单位、数据类型
- 定义清晰的标签生成规则

### ✅ 可扩展性
- 二分类 → 多类分类的演进路径
- 支持添加新特征（风速、海流、能见度等）
- 支持不确定性标签（为 EDL 做准备）

### ✅ 工程化
- Parquet 格式便于大规模数据处理
- 元数据规范便于数据追溯和复现
- 数据质量检查清单完整

### ✅ 实用性
- 包含 Python 伪代码框架
- 数据生成流程清晰
- 参考资源完整

---

## 📝 文档结构

```
docs/EDL_TRAINING_DATA_DESIGN.md
├── 1. 概述
├── 2. 输入特征（Features）
│   ├── 2.1 环保特征
│   ├── 2.2 船舶特征
│   └── 2.3 特征说明
├── 3. 输出标签（Targets）
│   ├── 3.1 简单版本：二分类
│   └── 3.2 扩展版本：多类分类
├── 4. 数据文件格式
│   ├── 4.1 推荐格式：Parquet
│   ├── 4.2 文件组织
│   ├── 4.3 Parquet 列定义
│   └── 4.4 元数据文件
├── 5. 数据生成流程
│   ├── 5.1 高层流程
│   └── 5.2 Python 伪代码框架
├── 6. 数据质量检查清单
├── 7. 后续扩展方向
├── 8. 参考资源
└── 9. 版本历史
```

---

## 🚀 后续步骤

### E0.2：实现数据导出脚本
- 从原始 AIS + 环境数据生成 Parquet 训练集
- 实现标签生成逻辑
- 数据清洗和验证

### E0.3：建立最小训练闭环
- 数据加载模块
- 模型训练脚本（PyTorch + EDL）
- 评估指标计算

### E0.4：快速评估工具
- 数据质量检查
- 模型初步性能评估
- 训练日志和可视化

---

## 📌 关键决策

1. **二分类优先**: 从简单的 Safe/Risky 开始，后续扩展到多类
2. **Parquet 格式**: 优于 CSV，适合大规模训练
3. **规则化标签**: 使用明确的阈值和风险评分，便于初期验证
4. **时间分割**: 按时间顺序分割数据，避免数据泄露

---

## 📚 相关文件

- **主文档**: `docs/EDL_TRAINING_DATA_DESIGN.md`
- **任务清单**: `PHASE_EDL0_TASK_E0.1_COMPLETION.md`（本文件）

---

## ✨ 总结

E0.1 任务已圆满完成。我们为 EDL 模型定义了：
- ✅ 清晰的输入特征（10 维）
- ✅ 明确的输出标签（二分类 + 扩展路径）
- ✅ 高效的数据格式（Parquet）
- ✅ 完整的元数据规范
- ✅ 数据生成流程和伪代码

这为后续的数据导出、模型训练和评估奠定了坚实的基础。

**下一步**: 开始 E0.2 任务，实现数据导出脚本。









